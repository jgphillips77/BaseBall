{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HanksTeam](https://baseballhall.org/sites/default/files/styles/header_image_1800_w/public/Aaron%20Hank%20312.68_Grp_NBL.jpg?itok=ekmrvcZs \"Hank Aaron poses with fellow Hall of Famer Eddie Mathews (center), and Braves first baseman Joe Adcock, while playing for the Milwaukee Braves. (National Baseball Hall of Fame)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is a neural network better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/johnphillips/Desktop/DSI-Class-Stuff/BaseBall\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start with reading the data sets from the pickles\n",
    "teams = pd.read_pickle('data/teams.p')\n",
    "teams_num = pd.read_pickle('data/teams_num.p')\n",
    "new_reduced = pd.read_pickle('data/new_reduced.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Separate X and y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Had to also drop Wins, Losses, and WinP since those are direct indicators.\n",
    "# And they are not part of a players individual stats.\n",
    "X = teams_num.drop(['WSWin', 'LgWin', 'W', 'L', 'WinP'], axis=1) \n",
    "\n",
    "# Make a y2 based upon Winning Leage Series, for possible second model.\n",
    "y = teams_num['WSWin']\n",
    "y2 = teams_num['LgWin'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train-test split our data...\n",
    "\n",
    "# Standard split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.33)\n",
    "\n",
    "# Second split based upon LgWin target:\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state = 42, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't forget scaled data:\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnphillips/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1899, 36), (1899,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to fix the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "y_train = y_train.values.reshape(y_train.shape[0], 1)\n",
    "#y_test = y_test.values.reshape(y_train.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1899, 36, 1), (1899, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1899/1899 [==============================] - 1s 274us/step - loss: 0.7617 - acc: 0.9521\n",
      "Epoch 2/10\n",
      "1899/1899 [==============================] - 0s 68us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 3/10\n",
      "1899/1899 [==============================] - 0s 72us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 4/10\n",
      "1899/1899 [==============================] - 0s 65us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 5/10\n",
      "1899/1899 [==============================] - 0s 65us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 6/10\n",
      "1899/1899 [==============================] - 0s 74us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 7/10\n",
      "1899/1899 [==============================] - 0s 67us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 8/10\n",
      "1899/1899 [==============================] - 0s 65us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 9/10\n",
      "1899/1899 [==============================] - 0s 68us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 10/10\n",
      "1899/1899 [==============================] - 0s 70us/step - loss: 0.7299 - acc: 0.9547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a23020e50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(36,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1899/1899 [==============================] - 1s 362us/step - loss: 0.8104 - acc: 0.9489\n",
      "Epoch 2/10\n",
      "1899/1899 [==============================] - 0s 70us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 3/10\n",
      "1899/1899 [==============================] - 0s 71us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 4/10\n",
      "1899/1899 [==============================] - 0s 70us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 5/10\n",
      "1899/1899 [==============================] - 0s 69us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 6/10\n",
      "1899/1899 [==============================] - 0s 69us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 7/10\n",
      "1899/1899 [==============================] - 0s 69us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 8/10\n",
      "1899/1899 [==============================] - 0s 69us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 9/10\n",
      "1899/1899 [==============================] - 0s 69us/step - loss: 0.7299 - acc: 0.9547\n",
      "Epoch 10/10\n",
      "1899/1899 [==============================] - 0s 71us/step - loss: 0.7299 - acc: 0.9547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a23802ed0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different Optimizer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(36,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1899/1899 [==============================] - 1s 551us/step - loss: 4.6814 - acc: 0.7062\n",
      "Epoch 2/20\n",
      "1899/1899 [==============================] - 0s 186us/step - loss: 5.5565 - acc: 0.6509\n",
      "Epoch 3/20\n",
      "1899/1899 [==============================] - 0s 189us/step - loss: 5.1678 - acc: 0.6761\n",
      "Epoch 4/20\n",
      "1899/1899 [==============================] - 1s 346us/step - loss: 4.0099 - acc: 0.7488\n",
      "Epoch 5/20\n",
      "1899/1899 [==============================] - 0s 207us/step - loss: 3.0776 - acc: 0.8073\n",
      "Epoch 6/20\n",
      "1899/1899 [==============================] - 0s 196us/step - loss: 2.2905 - acc: 0.8568\n",
      "Epoch 7/20\n",
      "1899/1899 [==============================] - 0s 194us/step - loss: 2.4662 - acc: 0.8457\n",
      "Epoch 8/20\n",
      "1899/1899 [==============================] - 0s 189us/step - loss: 2.5002 - acc: 0.8436\n",
      "Epoch 9/20\n",
      "1899/1899 [==============================] - 0s 190us/step - loss: 2.2401 - acc: 0.8599\n",
      "Epoch 10/20\n",
      "1899/1899 [==============================] - 0s 191us/step - loss: 2.2814 - acc: 0.8573\n",
      "Epoch 11/20\n",
      "1899/1899 [==============================] - 1s 338us/step - loss: 2.3241 - acc: 0.8547\n",
      "Epoch 12/20\n",
      "1899/1899 [==============================] - 0s 216us/step - loss: 2.2653 - acc: 0.8583\n",
      "Epoch 13/20\n",
      "1899/1899 [==============================] - 0s 192us/step - loss: 2.4249 - acc: 0.8483\n",
      "Epoch 14/20\n",
      "1899/1899 [==============================] - 0s 196us/step - loss: 2.2827 - acc: 0.8573\n",
      "Epoch 15/20\n",
      "1899/1899 [==============================] - 0s 185us/step - loss: 1.4096 - acc: 0.9121\n",
      "Epoch 16/20\n",
      "1899/1899 [==============================] - 0s 254us/step - loss: 1.3088 - acc: 0.9184\n",
      "Epoch 17/20\n",
      "1899/1899 [==============================] - 1s 303us/step - loss: 1.0154 - acc: 0.9368\n",
      "Epoch 18/20\n",
      "1899/1899 [==============================] - 0s 188us/step - loss: 0.9146 - acc: 0.9431\n",
      "Epoch 19/20\n",
      "1899/1899 [==============================] - 0s 210us/step - loss: 0.8559 - acc: 0.9468\n",
      "Epoch 20/20\n",
      "1899/1899 [==============================] - 0s 180us/step - loss: 0.9059 - acc: 0.9437\n",
      "936/936 [==============================] - 0s 74us/step\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification Model:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(36, 1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=20,\n",
    "          )\n",
    "score = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 36, 64)            128       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 147,713\n",
      "Trainable params: 147,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/936 [==============================] - 0s 74us/step\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9668803418803419"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_probas = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnphillips/anaconda2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:52: FutureWarning: 'argmax' is deprecated. Use 'idxmax' instead. The behavior of 'argmax' will be corrected to return the positional maximum in the future. Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1110"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
